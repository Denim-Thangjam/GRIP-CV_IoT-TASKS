{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b827a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84990bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "# Transfering the weights and cfg from yolov3_416\n",
    "# Using the coco.names as labels\n",
    "\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "classes = []\n",
    "with open('coco.names','r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "    \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8ef0c0",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efc04fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the image\n",
    "\n",
    "img = cv2.imread('Trial4.jpg')\n",
    "height, width, _ = img.shape\n",
    "\n",
    "## Preparing the image\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "boxes=[]\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "## Visualization\n",
    "## extracts all info from the layer's output\n",
    "for output in layerOutputs:\n",
    "    ## extracts info from each of the outputs\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            \n",
    "            ## Finding the coordinates of the center, and measurement of width and height of box.\n",
    "            ## As we had normalized the values,\n",
    "            ## so we need to multiply it with original size to get the correct coordinates\n",
    "            center_x = int(detection[0]*width)\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "            ## Yolo detects the center of the boxes,\n",
    "            ## So in order to work with OpenCV, we need to find the top left corner dims\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            \n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "            \n",
    "\n",
    "# print(len(boxes))\n",
    "## To remove the overlap of boxes on a single object, we'll use the Non Maximum Supression\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "# print(indexes.flatten())\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "\n",
    "## Loop to identify each of the object detected\n",
    "for i in indexes.flatten():\n",
    "    x, y, w, h = boxes[i]\n",
    "    label = str(classes[class_ids[i]])\n",
    "    confidence = str(round(confidences[i], 2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
    "\n",
    "## Viewing the image\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a0c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d670813f",
   "metadata": {},
   "source": [
    "## Video (Accurate but very slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c77aef",
   "metadata": {},
   "source": [
    "\n",
    "cap = cv2.VideoCapture('screen-capture.mp4')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cap.read()\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "    boxes=[]\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
    "    \n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow('Image', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e674f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
